{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating train split: 52 examples [00:00, 642.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files={'train': './datas/training_text_personal_data.csv'},\n",
    "    delimiter=';',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"neuralmind/bert-base-portuguese-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    return tokenizer(data['text'], padding='max_length', truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<00:00, 771.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset['train'].map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(tokenized_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando o Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iqued\\PUC_rio\\mvp_machine_learning_and_analytics\\venv\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\iqued\\AppData\\Local\\Temp\\ipykernel_7900\\2385051996.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "  0%|          | 0/18 [22:30<?, ?it/s]\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [01:49<02:50, 14.22s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                              \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [01:56<02:50, 14.22s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0028258562088013, 'eval_runtime': 6.4798, 'eval_samples_per_second': 1.698, 'eval_steps_per_second': 0.309, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [03:33<01:22, 13.72s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                               \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [03:39<01:22, 13.72s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9608098864555359, 'eval_runtime': 6.4826, 'eval_samples_per_second': 1.697, 'eval_steps_per_second': 0.309, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [05:17<00:00, 14.10s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                               \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [05:28<00:00, 14.10s/it]\n",
      "\u001b[A\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [05:28<00:00, 18.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9470769762992859, 'eval_runtime': 6.1459, 'eval_samples_per_second': 1.79, 'eval_steps_per_second': 0.325, 'epoch': 3.0}\n",
      "{'train_runtime': 328.7599, 'train_samples_per_second': 0.374, 'train_steps_per_second': 0.055, 'train_loss': 1.0253802405463324, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.10it/s]\n",
      "c:\\Users\\iqued\\PUC_rio\\mvp_machine_learning_and_analytics\\venv\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\iqued\\AppData\\Local\\Temp\\ipykernel_7900\\2385051996.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para o Fold 1: {'eval_loss': 0.9470769762992859, 'eval_runtime': 6.2071, 'eval_samples_per_second': 1.772, 'eval_steps_per_second': 0.322, 'epoch': 3.0}\n",
      "Treinando o Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [01:39<02:42, 13.54s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                              \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [01:46<02:42, 13.54s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8630594611167908, 'eval_runtime': 6.4214, 'eval_samples_per_second': 1.713, 'eval_steps_per_second': 0.311, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [03:26<01:21, 13.61s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                               \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [03:32<01:21, 13.61s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8196222186088562, 'eval_runtime': 6.5194, 'eval_samples_per_second': 1.687, 'eval_steps_per_second': 0.307, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [05:07<00:00, 13.36s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                               \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [05:16<00:00, 13.36s/it]\n",
      "\u001b[A\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [05:16<00:00, 17.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8099384307861328, 'eval_runtime': 5.9974, 'eval_samples_per_second': 1.834, 'eval_steps_per_second': 0.333, 'epoch': 3.0}\n",
      "{'train_runtime': 316.1875, 'train_samples_per_second': 0.389, 'train_steps_per_second': 0.057, 'train_loss': 0.8562533060709635, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.07it/s]\n",
      "c:\\Users\\iqued\\PUC_rio\\mvp_machine_learning_and_analytics\\venv\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\iqued\\AppData\\Local\\Temp\\ipykernel_7900\\2385051996.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para o Fold 2: {'eval_loss': 0.8099384307861328, 'eval_runtime': 6.947, 'eval_samples_per_second': 1.583, 'eval_steps_per_second': 0.288, 'epoch': 3.0}\n",
      "Treinando o Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [01:44<02:53, 14.48s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                              \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [01:51<02:53, 14.48s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.61440509557724, 'eval_runtime': 6.3485, 'eval_samples_per_second': 1.575, 'eval_steps_per_second': 0.315, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [03:28<01:25, 14.17s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                               \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [03:34<01:25, 14.17s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5808447003364563, 'eval_runtime': 6.0561, 'eval_samples_per_second': 1.651, 'eval_steps_per_second': 0.33, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [05:10<00:00, 14.09s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                               \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [05:18<00:00, 14.09s/it]\n",
      "\u001b[A\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [05:18<00:00, 17.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5600932240486145, 'eval_runtime': 5.8576, 'eval_samples_per_second': 1.707, 'eval_steps_per_second': 0.341, 'epoch': 3.0}\n",
      "{'train_runtime': 318.4166, 'train_samples_per_second': 0.396, 'train_steps_per_second': 0.057, 'train_loss': 0.6745323075188531, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.78it/s]\n",
      "c:\\Users\\iqued\\PUC_rio\\mvp_machine_learning_and_analytics\\venv\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para o Fold 3: {'eval_loss': 0.5600932240486145, 'eval_runtime': 5.6719, 'eval_samples_per_second': 1.763, 'eval_steps_per_second': 0.353, 'epoch': 3.0}\n",
      "Treinando o Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iqued\\AppData\\Local\\Temp\\ipykernel_7900\\2385051996.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [01:40<02:50, 14.25s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                              \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [01:46<02:50, 14.25s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.525206446647644, 'eval_runtime': 5.7654, 'eval_samples_per_second': 1.734, 'eval_steps_per_second': 0.347, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [03:23<01:25, 14.30s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                               \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [03:29<01:25, 14.30s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.49075180292129517, 'eval_runtime': 5.4566, 'eval_samples_per_second': 1.833, 'eval_steps_per_second': 0.367, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [05:12<00:00, 15.09s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                               \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [05:22<00:00, 15.09s/it]\n",
      "\u001b[A\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [05:22<00:00, 17.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.47197189927101135, 'eval_runtime': 4.8958, 'eval_samples_per_second': 2.043, 'eval_steps_per_second': 0.409, 'epoch': 3.0}\n",
      "{'train_runtime': 322.4589, 'train_samples_per_second': 0.391, 'train_steps_per_second': 0.056, 'train_loss': 0.4196605682373047, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.94it/s]\n",
      "c:\\Users\\iqued\\PUC_rio\\mvp_machine_learning_and_analytics\\venv\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\iqued\\AppData\\Local\\Temp\\ipykernel_7900\\2385051996.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para o Fold 4: {'eval_loss': 0.47197189927101135, 'eval_runtime': 5.45, 'eval_samples_per_second': 1.835, 'eval_steps_per_second': 0.367, 'epoch': 3.0}\n",
      "Treinando o Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [01:30<02:32, 12.75s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                              \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [01:36<02:32, 12.75s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.251351535320282, 'eval_runtime': 5.563, 'eval_samples_per_second': 1.798, 'eval_steps_per_second': 0.36, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [03:07<01:18, 13.15s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                               \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [03:12<01:18, 13.15s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22464656829833984, 'eval_runtime': 5.2799, 'eval_samples_per_second': 1.894, 'eval_steps_per_second': 0.379, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [04:51<00:00, 14.00s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                               \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [05:00<00:00, 14.00s/it]\n",
      "\u001b[A\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [05:00<00:00, 16.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20889540016651154, 'eval_runtime': 4.8407, 'eval_samples_per_second': 2.066, 'eval_steps_per_second': 0.413, 'epoch': 3.0}\n",
      "{'train_runtime': 300.6342, 'train_samples_per_second': 0.419, 'train_steps_per_second': 0.06, 'train_loss': 0.2668522728814019, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para o Fold 5: {'eval_loss': 0.20889540016651154, 'eval_runtime': 5.0383, 'eval_samples_per_second': 1.985, 'eval_steps_per_second': 0.397, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(kf.split(tokenized_dataset)):\n",
    "    print(f\"Treinando o Fold {fold + 1}\")\n",
    "    \n",
    "    train_data = tokenized_dataset.select(train_index)\n",
    "    test_data = tokenized_dataset.select(test_index)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./datas/results_fold_{fold + 1}\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        num_train_epochs=3,\n",
    "        save_total_limit=1,\n",
    "        logging_dir=f\"./logs_fold_{fold + 1}\",\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=test_data,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    eval_result = trainer.evaluate()\n",
    "    results.append(eval_result)\n",
    "    print(f\"Resultados para o Fold {fold + 1}: {eval_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de Cross-Validation: [{'eval_loss': 0.9470769762992859, 'eval_runtime': 6.2071, 'eval_samples_per_second': 1.772, 'eval_steps_per_second': 0.322, 'epoch': 3.0}, {'eval_loss': 0.8099384307861328, 'eval_runtime': 6.947, 'eval_samples_per_second': 1.583, 'eval_steps_per_second': 0.288, 'epoch': 3.0}, {'eval_loss': 0.5600932240486145, 'eval_runtime': 5.6719, 'eval_samples_per_second': 1.763, 'eval_steps_per_second': 0.353, 'epoch': 3.0}, {'eval_loss': 0.47197189927101135, 'eval_runtime': 5.45, 'eval_samples_per_second': 1.835, 'eval_steps_per_second': 0.367, 'epoch': 3.0}, {'eval_loss': 0.20889540016651154, 'eval_runtime': 5.0383, 'eval_samples_per_second': 1.985, 'eval_steps_per_second': 0.397, 'epoch': 3.0}]\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultados de Cross-Validation:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÃ©dia do eval_loss: 0.5996\n"
     ]
    }
   ],
   "source": [
    "eval_losses = [0.9471, 0.8099, 0.5601, 0.4720, 0.2089]\n",
    "mean_loss = sum(eval_losses) / len(eval_losses)\n",
    "print(f\"MÃ©dia do eval_loss: {mean_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training_args = TrainingArguments(\n",
    "    output_dir=\"./final_model\",\n",
    "    eval_strategy=\"no\",  # Desativar avaliaÃ§Ã£o, pois a validaÃ§Ã£o cruzada jÃ¡ foi feita\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    save_total_limit=1,\n",
    "    logging_dir=\"./final_logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=final_training_args,\n",
    "    train_dataset=tokenized_dataset, \n",
    "    processing_class=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [1:08:15<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [06:28<00:00, 18.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 388.7701, 'train_samples_per_second': 0.401, 'train_steps_per_second': 0.054, 'train_loss': 0.12189194134303502, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21, training_loss=0.12189194134303502, metrics={'train_runtime': 388.7701, 'train_samples_per_second': 0.401, 'train_steps_per_second': 0.054, 'total_flos': 41045693165568.0, 'train_loss': 0.12189194134303502, 'epoch': 3.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo final treinado e salvo em './final_model'\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"./final_model\")\n",
    "tokenizer.save_pretrained(\"./final_model\")\n",
    "\n",
    "print(\"Modelo final treinado e salvo em './final_model'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
